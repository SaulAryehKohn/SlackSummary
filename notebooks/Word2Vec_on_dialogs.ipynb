{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import spacy\n",
    "plt.style.use('ggplot')\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dialogues_text.txt') as file:\n",
    "    dialogs = [line.rstrip('\\n') for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_sp = [dlg.split(\"__eou__\")[:-1] for dlg in dialogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs = [dlg for dlg in dialogs_sp if len(dlg)>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)  # C binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs_nlpd_cleaned = []\n",
    "for i,dlg in enumerate(longer_dialogs):\n",
    "    tmp_dialog_stor = []\n",
    "    for j,sentence in enumerate(dlg):\n",
    "        sentarr = [w.lower() for w in sentence.split() if not w.lower() in stop_words and not len(w)<4]\n",
    "        nlp_sentarr = nlp(' '.join(sentarr))\n",
    "        nouns_sentarr = [tk.lemma_ for tk in nlp_sentarr if tk.pos_ in ['NOUN','PROPN']]\n",
    "        tmp_dialog_stor.append(nouns_sentarr)\n",
    "    longer_dialogs_nlpd_cleaned.append(tmp_dialog_stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_file = open('longer_nlpd_cleaned_lemmatized_array.pkl','wb')\n",
    "pickle.dump(longer_dialogs_nlpd_cleaned,pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'drink',\n",
       " 'order',\n",
       " 'aperitif',\n",
       " 'start',\n",
       " 'thank',\n",
       " 'signature',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'cocktail',\n",
       " 'stinger',\n",
       " 'lime',\n",
       " 'juice',\n",
       " 'grenadine']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.chain.from_iterable(longer_dialogs_nlpd_cleaned[501]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wine_spritzer', 0.706296443939209),\n",
       " ('unsweetened_iced_tea', 0.687741219997406),\n",
       " ('unsweet_tea', 0.6812054514884949),\n",
       " ('triple_sec', 0.6755117177963257),\n",
       " ('drinks', 0.6749691963195801),\n",
       " ('Caipirinhas', 0.670561671257019),\n",
       " ('gin_martini', 0.6701815724372864),\n",
       " ('fizzy_citrus', 0.6674100160598755),\n",
       " ('glassful', 0.6648150682449341),\n",
       " ('martini', 0.6612378358840942)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=list(itertools.chain.from_iterable(longer_dialogs_nlpd_cleaned[501])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Believe it or not , tea is the most popular beverage in the world after water . ',\n",
       " ' Well , people from Asia to Europe all enjoy tea . ',\n",
       " ' Right . And China is the homeland of tea . ',\n",
       " \" Yes , Chinese people love drinking tea so much . Some even claim they can't live without tea . \",\n",
       " ' Do you know there are several catagories of Chinese tea ? ',\n",
       " ' Yes , I believe there are green teas , black teas and scented teas . Any Others ? ',\n",
       " ' Well , have you ever heard of Oulong tea and compressed tea ? ',\n",
       " \" Oh , yeah . Oulong tea is good for one's health . isn't it ? \",\n",
       " ' You surely know a lot about Chinese tea . ',\n",
       " ' Sure , I like drinking tea at teahouses . ',\n",
       " ' Oh , so do I . ',\n",
       " \" Why don't we go for one now ? \",\n",
       " ' Great . We can chat while enjoying a cup there . ',\n",
       " \" Let's go ! \",\n",
       " '']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_dialogs[512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kys = list(itertools.chain.from_iterable(longer_dialogs_nlpd_cleaned[512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [(k in word_vectors.vocab) for k in kys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shape_Angius', 0.687379002571106),\n",
       " ('THC_infused_lozenges', 0.5973172187805176),\n",
       " ('pancakes_sausage_orange_juice', 0.570042610168457),\n",
       " ('Wolfgang_Puck_gourmet', 0.5698696970939636),\n",
       " ('UDBKL', 0.5656538009643555),\n",
       " ('juice_Leclerc', 0.5617351531982422),\n",
       " ('coffee', 0.5509310364723206),\n",
       " ('CDMHY', 0.5456836223602295),\n",
       " ('decaffeinated_brew', 0.5453557968139648),\n",
       " ('KF_OOE', 0.5437560081481934)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "word_vectors.most_similar(positive=list(compress(kys, lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
